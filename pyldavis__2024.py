# -*- coding: utf-8 -*-
"""pyLDAvis__2024.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1TB7OoOPrSl8pUqffUfyAhKL6pMwKFxC1
"""

pip install pyLDAvis

import gensim
from gensim.parsing.preprocessing import preprocess_string
from gensim.corpora.dictionary import Dictionary
from gensim.models.ldamodel import LdaModel
import pyLDAvis.gensim_models as gensimvis

import re
import nltk
nltk.download('stopwords')
from nltk.corpus import stopwords

def preprocess_string(text,
                   lowercase=True,
                   remove_punctuation=True,
                   remove_stopwords=True,
                   remove_digits=False,
                   stemming=False,
                   lemmatization=False):
  """
  Preprocesses text data by applying various cleaning and normalization techniques.

  Args:
      text: The text string to be preprocessed.
      lowercase: Convert text to lowercase (default: True).
      remove_punctuation: Remove punctuation characters (default: True).
      remove_stopwords: Remove common stopwords (default: True).
      remove_digits: Remove digits (default: False).
      stemming: Apply stemming to reduce words to their base form (default: False).
      lemmatization: Apply lemmatization to reduce words to their dictionary form (default: False).

  Returns:
      The preprocessed text string.
  """

  # Convert text to lowercase
  if lowercase:
      text = text.lower()

  # Remove punctuation
  if remove_punctuation:
      text = re.sub(r'[^\w\s]', '', text)

  # Remove stopwords
  if remove_stopwords:
      stop_words = stopwords.words('english')
      text = [word for word in text.split() if word not in stop_words]

  # Remove digits
  if remove_digits:
      text = re.sub(r'\d+', '', text)

  # Apply stemming or lemmatization (choose one)
  if stemming:
      from nltk.stem import PorterStemmer
      stemmer = PorterStemmer()
      text = [stemmer.stem(word) for word in text.split()]
  elif lemmatization:
      from nltk.stem import WordNetLemmatizer
      lemmatizer = WordNetLemmatizer()
      text = [lemmatizer.lemmatize(word) for word in text.split()]

  return text

documents = [
    # Technology
    "Quantum computing holds the potential to revolutionize various fields.",
    "The ethical implications of artificial intelligence remain a critical discussion point.",
    "Social media platforms face growing pressure to address online misinformation.",

    # Science
    "Climate change is causing more extreme weather events around the globe.",
    "New discoveries in genetics are unlocking secrets about human health and disease.",
    "Space exploration continues to push the boundaries of human understanding.",

    # History
    "The Renaissance marked a flourishing of art, literature, and science in Europe.",
    "The Civil Rights Movement fought for racial equality in the United States.",
    "The invention of the printing press revolutionized communication and knowledge sharing.",

    # Travel
    "Experiencing different cultures broadens our perspectives and understanding of the world.",
    "Ecotourism promotes sustainable travel practices that protect natural environments.",
    "Solo travel can be a transformative experience for personal growth and self-discovery.",

    # Art and Literature
    "Music has the power to evoke emotions and connect people across cultures.",
    "Great literature provides insights into human nature and the complexities of life.",
    "Modern art challenges traditional conventions and sparks new ways of thinking.",

    # Sports
    "The Olympics celebrate athletic achievement and unite nations in peaceful competition.",
    "Teamwork and collaboration are essential for success in many sports.",
    "Pushing one's limits and overcoming challenges can be rewarding in both sports and life.",

    # Food and Culture
    "Diverse culinary traditions reflect the unique stories and flavors of different regions.",
    "Sharing meals with loved ones creates lasting memories and strengthens bonds.",
    "Food can be a powerful tool for cultural exchange and understanding.",

    # Philosophy and Psychology
    "Critical thinking allows us to question assumptions and develop well-informed opinions.",
    "Understanding human emotions and behaviors can improve our interactions with others.",
    "Finding meaning and purpose in life is a lifelong journey with individual answers.",

    # Miscellaneous
    "Laughter is the best medicine, so keep smiling and stay positive.",
    "Be kind to yourself and others, because everyone is fighting their own battles.",
    "Never stop learning and growing, as there is always something new to discover.",
]

processed_docs = [preprocess_string(doc) for doc in documents]

dictionary = Dictionary(processed_docs)
corpus = [dictionary.doc2bow(doc) for doc in processed_docs]

num_topics = 9
lda_model = LdaModel(corpus, id2word=dictionary, num_topics=num_topics)

vis_data = gensimvis.prepare(lda_model, corpus, dictionary)

# Jupyter Notebook:
gensimvis.pyLDAvis.display(vis_data)

# Other environments:
gensimvis.pyLDAvis.save_html(vis_data, 'lda_visualization.html')

gensimvis.pyLDAvis.display